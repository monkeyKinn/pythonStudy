<!-- TOC -->
* [笔记](#笔记)
  * [基本使用](#基本使用)
  * [一个类型六个方法](#一个类型六个方法)
  * [下载](#下载)
  * [请求对象的定制](#请求对象的定制)
  * [get请求的quote](#get请求的quote)
  * [get请求的urlencode](#get请求的urlencode)
  * [post请求的百度翻译(sug)](#post请求的百度翻译--sug-)
    * [注意:](#注意-)
  * [百度翻译详解接口(v2transapi)](#百度翻译详解接口--v2transapi-)
  * [ajax的get请求](#ajax的get请求)
  * [ajax的post请求](#ajax的post请求)
  * [异常](#异常)
    * [URLError\HTTPError](#urlerrorhttperror)
  * [cookie登录](#cookie登录)
  * [handle处理器](#handle处理器)
  * [代理服务器](#代理服务器)
  * [代理池](#代理池)
<!-- TOC -->

# 笔记

## 基本使用

## 一个类型六个方法

## 下载

## 请求对象的定制

## get请求的quote
    在url中,有涉及到中文的,就需要依赖于urllib的parse的quote
```python
import urllib.parse
# eq获取源码:https://www.baidu.com/s?wd=%E5%91%A8%E6%9D%B0%E4%BC%A6
name = urllib.parse.quote('周杰伦')
url = 'https://www.baidu.com/s?wd='
# 加号两端都是字符串 所以可以直接加
url += name
```
## get请求的urlencode
应用场景:  有多个参数的时候
```python
# url = 'https://www.baidu.com/s?wd=周杰伦&sex=男'
import urllib.parse

base_url = 'https://www.baidu.com/s?'
data = {
    'wd': '周杰伦',
    'sex': '男',
    'location': '中国台湾省'
}
url = base_url + urllib.parse.urlencode(data)

```
## post请求的百度翻译(sug)
### 注意:
    1.post请求的参数必须编码(urlencode)      在url编码之后再进行编码
        data = {
            'kw': 'spider'
        }
        load = urllib.parse.urlencode(data).encode('utf-8')
    2.post的请求的参数是不会拼接在Url的后面的，而是需要放在请求对象定制的参数中
        req = urllib.request.Request(url=url, data=load, headers=headers)

## 百度翻译详解接口(v2transapi)

## ajax的get请求
    下载到本地
        open方法默认使用gbk编码,如果要想保存汉字,需要指定编码格式
        fp = open('douban.json','w',encoding='utf-8')
        fp.write(content) 
    以上两句话可以等价于下面
        with open('douban.json', 'w', encoding='utf-8') as fp:
        fp.write(content)
## ajax的post请求
    注意post请求要编码,然后放到请求对象的定制的参数里
## 异常

### URLError\HTTPError

```text
简介:
  1.HTTPError类是URLError类的子类
  2.导入的包urllib.error.HTTPError  urllib.error.URLError
  3.http错误：http错误是针对浏览器无法连接到服务器而增加出来的错误提示。引导并告诉浏览者该页是哪里出了问题。
  4.通过urllib发送请求的时候，有可能会发送失败，这个时候如果想让你的代码更加的健壮，可以通过try‐except进行捕获异常，
    异常有两类，URLError\HTTPError
```

```python
import urllib.error
try:
    XXX
except urllib.error.HTTPError as e:
    print('系统正在升级')
except urllib.error.URLError as e:
    print('无响应')
```

## cookie登录

    详见13+14

## handle处理器

```text
为什么要学习handler？
    urllib.request.urlopen(url)
        不能定制请求头
    urllib.request.Request(url,headers,data)
        可以定制请求头
    Handler
        定制更高级的请求头
            (
                随着业务逻辑的复杂 请求对象的定制已经满足不了我们的需求
                （动态cookie和代理不能使用请求对象的定制）
            )
```

```python
import urllib.request

url = 'http://www.baidu.com'
headers = {
    'User‐Agent': 'Mozilla/5.0(WindowsNT10.0;Win64;x64)AppleWebKit/537.36(KHTML,likeGecko)Chrome/74.0.3729.169Safari/537.36'
}
request = urllib.request.Request(url=url, headers=headers)

handler = urllib.request.HTTPHandler()
opener = urllib.request.build_opener(handler)
response = opener.open(request)
print(response.read().decode('utf‐8'))
```

## 代理服务器
```text
1.代理的常用功能?
    1.突破自身IP访问限制，访问国外站点。 
    2.访问一些单位或团体内部资源 
        扩展：某大学FTP(前提是该代理地址在该资源的允许访问范围之内)，使用教育网内地址段免费代理服务器，就可以用于对教育网开放的各类FTP下载上传，以及各类资料查询共享等服务。
3.提高访问速度 
    扩展：通常代理服务器都设置一个较大的硬盘缓冲区，当有外界的信息通过时，同时也将其保存到缓冲区中，当其他用户再访问相同的信息时，则直接由缓冲区中取出信息，传给用户，以提高访问速度。
4.隐藏真实IP 
    扩展：上网者也可以通过这种方法隐藏自己的IP，免受攻击。 
2.代码配置代理
    1.创建Reuqest对象 
    2.创建ProxyHandler对象 
    3.用handler对象创建opener对象 
    4.使用opener.open函数发送请求 
```
## 代理池
    找到了一个肥肠好用的免费代理网站
    https://ip.jiangxianli.com/blog/23562.html
    不知道啥时候失效...
    另外,校验是否用了代理别用百度了 真的垃圾 找到了一个 http://www.dingk.cn/IP/